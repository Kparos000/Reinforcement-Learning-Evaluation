# Configuration for RL-ACE Evaluation Framework
# This file controls all hyperparameters, model settings, and evaluation parameters

# Model Configuration
model:
  provider: "anthropic"  # anthropic, openai, or huggingface
  name: "claude-3-5-haiku-latest"
  max_tokens: 400
  temperature: 0.45
  top_p: 0.9

# Grader Configuration
grader:
  concision_limit: 0.60  # Max 60% of original character count
  word_cap: 16          # Max words in rewrite
  min_delta_words: 6    # Minimum words in delta_update
  strict_mode: true     # Fail on any validation error

# Evaluation Configuration
evaluation:
  num_runs: 10
  random_seed: 42
  max_words_variation: [12, 14, 16]  # Per-run word cap variation
  parallel_workers: 4

# RL Algorithm Configuration
rl:
  algorithm: "best_of_n"  # best_of_n, reinforce, ppo
  reward_scheme: "binary"  # binary, partial (Phase 2), dense (Phase 3)

  # Best-of-N specific
  best_of_n:
    n_samples: 5
    temperature: 1.0  # High temp for diversity
    early_stop: true  # Stop if perfect reward achieved
    ablation_n_values: [1, 3, 5, 10, 20]  # For ablation study

  # REINFORCE specific (Phase 2)
  reinforce:
    learning_rate: 0.001
    gamma: 1.0  # Discount factor (1.0 for single-step)
    baseline: "moving_average"  # none, moving_average, learned
    n_samples: 5  # Samples per training iteration

  # PPO specific (Phase 3)
  ppo:
    learning_rate: 0.0003
    gamma: 1.0
    clip_epsilon: 0.2
    epochs: 4
    batch_size: 64
    n_samples: 10

# Scenarios Configuration
scenarios:
  # Phase 1: Short scenarios
  enabled:
    - report_long

  # Per-scenario settings can override defaults
  economics:
    concision_limit: 0.60
  medical:
    concision_limit: 0.65  # Slightly more lenient for medical terms
  legal:
    concision_limit: 0.55  # Stricter for legal precision
  scientific:
    concision_limit: 0.60

  # Phase 2: Long-form scenarios (1500-2500 chars, 30 facts)
  medical_long:
    concision_limit: 0.60
    word_cap: 120  # Allow more words for longer documents
  business_long:
    concision_limit: 0.60
    word_cap: 120
  legal_long:
    concision_limit: 0.60
    word_cap: 120
  report_long:
    concision_limit: 0.70
    word_cap: 140

# Visualization Configuration
visualization:
  enabled: true
  output_dir: "results/visualizations"
  formats: ["png", "pdf"]
  dpi: 300

# Experiment Tracking
tracking:
  enabled: false
  backend: "mlflow"  # mlflow or wandb
  experiment_name: "ace-rl-evaluation"
  run_name: null  # Auto-generated if null

# Logging Configuration
logging:
  level: "INFO"  # DEBUG, INFO, WARNING, ERROR
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
  file: "logs/ace_evaluation.log"

# Reproducibility
reproducibility:
  seed: 42
  deterministic: true
  benchmark: false  # Set to true for performance benchmarking
